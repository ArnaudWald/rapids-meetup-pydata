{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAPIDS.ai and Deep Learning with PyTorch\n",
    "\n",
    "In this notebook, we'll tackle the compatibility of the [RAPIDS.ai]() tools with major Deep Learning framework, i.e. PyTorch.\n",
    "\n",
    "We'll use an example dataset of relatively small size, just to show the improvements you can achieve already. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import cudf as gd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Modifying Data\n",
    "\n",
    "We are using the Electrolysia Time-Series Electricity Consumption Dataset from Kaggle, you can find more details about it [on the Kaggle dataset page](https://www.kaggle.com/utathya/electricity-consumption).\n",
    "\n",
    "Just for kicks, we can take this opportunity to compare loading times on CPU with `pandas` and GPU with `cuDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/electricity_consumption.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.6 ms, sys: 7.75 ms, total: 39.3 ms\n",
      "Wall time: 37.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pandas reading time\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.25 ms, sys: 0 ns, total: 3.25 ms\n",
      "Wall time: 2.25 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#pandas Transform\n",
    "minmax = MinMaxScaler().fit(df.iloc[:, 7].values.reshape((-1,1)).astype('float32'))\n",
    "df_time_series = minmax.transform(df.iloc[:, 7].values.reshape((-1,1)).astype('float32')).reshape((-1))\n",
    "df_time_series = pd.DataFrame(df_time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.2 ms, sys: 629 µs, total: 13.8 ms\n",
      "Wall time: 12.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#cudf reading\n",
    "cudf_data = gd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.5 ms, sys: 8.84 ms, total: 14.3 ms\n",
      "Wall time: 12.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#cudf transform\n",
    "minmax = MinMaxScaler().fit(cudf_data.iloc[:, 7].to_array().reshape((-1,1)).astype('float32'))\n",
    "cudf_time_series = minmax.transform(cudf_data.iloc[:, 7].to_array().reshape((-1,1)).astype('float32')).reshape((-1))\n",
    "cudf_time_series = gd.from_pandas(pd.DataFrame(cudf_time_series))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We see here that loading data from CSV is ~4 times faster on GPU. However, doing the `MinMaxScaler` operation is longer (by factor ~4 as well) because it is not available on cuDF : you need to fall back on CPU and pandas, multiplying the memory changes.\n",
    "\n",
    "### Pytorch Encoder\n",
    "\n",
    "Now what we want to do is to create a representation of data  or an encoding of data (for ex: a intermediate layer in resnet) . So, we will use a simple MLP autoencoder to do that. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building a Pytorch MLP model to get an intermediate representation of Data\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.dlpack import from_dlpack\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the network\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dimension= 32):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.first_layer_encoder = nn.Linear(input_size, hidden_size)\n",
    "        self.second_layer_encoder = nn.Linear(hidden_size, dimension)\n",
    "        self.first_layer_decoder = nn.Linear(dimension, hidden_size)\n",
    "        self.second_layer_decoder = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = nn.functional.relu(self.first_layer_encoder(input))\n",
    "        output = nn.functional.relu(self.second_layer_encoder(output))\n",
    "        decode = nn.functional.relu(self.first_layer_decoder(output))\n",
    "        decode = torch.sigmoid(self.second_layer_decoder(decode))\n",
    "        return decode, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training loop\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "input_size = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "def train_model(X, device):\n",
    "    \n",
    "    model = Encoder(input_size, hidden_size=32, dimension=32).to(device)\n",
    "    _X = X.to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        output, _ = model(_X)\n",
    "        loss = criterion(output, _X)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch) % 10 == 0:\n",
    "            print('epoch [{:02d}/{}], loss:{:.9f}'.format(epoch, num_epochs, loss.data))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the DataFrame into a PyTorch Tensor\n",
    "\n",
    "Now that we have done our preprocessing and defined the training algorithm, we need to give it an input. \n",
    "\n",
    "We will run the training on GPU, so we need to create a GPU Tensor.\n",
    "\n",
    "If we have a pandas DataFrame we can load it with `torch.from_numpy()` and send it to the GPU with `X.to(\"cuda:0\")`. Easy!\n",
    "\n",
    "Now, pytorch does not have a `from_cudf()` or `from_cupy()` method. If we want to combine PyTorch with a cuDF DataFrame, we could be naive and go back to a CPU numpy array, then convert this to a Tensor.\n",
    "\n",
    "As we can guess, and what we'll see below, this is far from optimal. So how can we go faster ?\n",
    "\n",
    "Thankfully, there is a package/format called [DLPack](https://github.com/dmlc/dlpack) that aims to do exactly this: transfer data while keeping it on GPU memory. It's built-in in PyTorch and in cuDF so it provides a nice alternative. The additional conversion step is still there, but we are now going pretty much as fast as the first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 822 µs, sys: 364 µs, total: 1.19 ms\n",
      "Wall time: 917 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Create a Tensor from a pandas DataFrame\n",
    "X_pandas = Variable(torch.from_numpy(df_time_series.values).float(), requires_grad=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.91 ms, sys: 3.53 ms, total: 6.45 ms\n",
      "Wall time: 5.58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a Tensor from a cuDF array \n",
    "# The naive way : go back on CPU with .as_matrix() then cast it back to GPU\n",
    "X_numpy = Variable(torch.from_numpy(cudf_time_series.as_matrix()).float(), requires_grad=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.5 ms, sys: 661 µs, total: 2.16 ms\n",
      "Wall time: 1.42 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda/lib/python3.6/site-packages/cudf/io/dlpack.py:83: UserWarning: WARNING: cuDF to_dlpack() produces column-major (Fortran order) output. If the output tensor needs to be row major, transpose the output of this function.\n",
      "  return cpp_dlpack.to_dlpack(gdf_cols)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a Tensor from a cuDF array \n",
    "# The right way : use the GPU-memory format DLPack handled by both cuDF and PyTorch\n",
    "\n",
    "X_dlpack = from_dlpack(cudf_time_series.to_dlpack()).unsqueeze(1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing training times\n",
    "\n",
    "Now all the three Tensors `X_pandas`, `X_numpy` and `X_dlpack` are essentially identical, we can do the classical _Training-on-CPU_ vs _Training-on-CPU_ time comparison. We get a more than 2x speedup factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [00/100], loss:0.151693329\n",
      "epoch [10/100], loss:0.012778017\n",
      "epoch [20/100], loss:0.016970651\n",
      "epoch [30/100], loss:0.006689673\n",
      "epoch [40/100], loss:0.002285680\n",
      "epoch [50/100], loss:0.000941366\n",
      "epoch [60/100], loss:0.000477169\n",
      "epoch [70/100], loss:0.000343223\n",
      "epoch [80/100], loss:0.000265637\n",
      "epoch [90/100], loss:0.000218914\n",
      "CPU times: user 2.64 s, sys: 4.14 s, total: 6.78 s\n",
      "Wall time: 682 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train on CPU\n",
    "model = train_model(X_dlpack, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [00/100], loss:0.170295894\n",
      "epoch [10/100], loss:0.009053732\n",
      "epoch [20/100], loss:0.017340804\n",
      "epoch [30/100], loss:0.007897619\n",
      "epoch [40/100], loss:0.003334319\n",
      "epoch [50/100], loss:0.000847001\n",
      "epoch [60/100], loss:0.000557288\n",
      "epoch [70/100], loss:0.000344462\n",
      "epoch [80/100], loss:0.000253610\n",
      "epoch [90/100], loss:0.000175861\n",
      "CPU times: user 186 ms, sys: 1.82 ms, total: 188 ms\n",
      "Wall time: 194 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train on CPU\n",
    "model = train_model(X_dlpack, 'cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end pipeline\n",
    "\n",
    "After comparing times step-by-step, let's compare a loading-to-training pipeline on CPU and GPU, let's start with CPU\n",
    "\n",
    "## CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [00/100], loss:0.199687675\n",
      "epoch [10/100], loss:0.011342634\n",
      "epoch [20/100], loss:0.017159335\n",
      "epoch [30/100], loss:0.007144428\n",
      "epoch [40/100], loss:0.004815394\n",
      "epoch [50/100], loss:0.001742429\n",
      "epoch [60/100], loss:0.000717756\n",
      "epoch [70/100], loss:0.000546714\n",
      "epoch [80/100], loss:0.000365689\n",
      "epoch [90/100], loss:0.000310298\n",
      "CPU times: user 2.39 s, sys: 2.72 s, total: 5.11 s\n",
      "Wall time: 539 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.dlpack import from_dlpack\n",
    "\n",
    "path = 'data/electricity_consumption.csv'\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "#Transform\n",
    "minmax = MinMaxScaler().fit(df.iloc[:, 7].values.reshape((-1,1)).astype('float32'))\n",
    "df_time_series = minmax.transform(df.iloc[:, 7].values.reshape((-1,1)).astype('float32')).reshape((-1))\n",
    "df_time_series = pd.DataFrame(df_time_series)\n",
    "\n",
    "# Build the network\n",
    "device = \"cpu\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dimension= 32):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.first_layer_encoder = nn.Linear(input_size, hidden_size)\n",
    "        self.second_layer_encoder = nn.Linear(hidden_size, dimension)\n",
    "        self.first_layer_decoder = nn.Linear(dimension, hidden_size)\n",
    "        self.second_layer_decoder = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = nn.functional.relu(self.first_layer_encoder(input))\n",
    "        output = nn.functional.relu(self.second_layer_encoder(output))\n",
    "        decode = nn.functional.relu(self.first_layer_decoder(output))\n",
    "        decode = torch.sigmoid(self.second_layer_decoder(decode))\n",
    "        return decode, output\n",
    "    \n",
    "# Define the training loop\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "input_size = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "def train_model(X, device):\n",
    "    \n",
    "    model = Encoder(input_size, hidden_size=32, dimension=32).to(device)\n",
    "    _X = X.to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        output, _ = model(_X)\n",
    "        loss = criterion(output, _X)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch) % 10 == 0:\n",
    "            print('epoch [{:02d}/{}], loss:{:.9f}'.format(epoch, num_epochs, loss.data))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load data into Tensor\n",
    "X = Variable(torch.from_numpy(df_time_series.values).float(), requires_grad=False).to(device)\n",
    "\n",
    "# Train model\n",
    "model = train_model(X, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU\n",
    "Now time to run the same on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [00/100], loss:0.203886509\n",
      "epoch [10/100], loss:0.019465458\n",
      "epoch [20/100], loss:0.017255634\n",
      "epoch [30/100], loss:0.016747575\n",
      "epoch [40/100], loss:0.006749355\n",
      "epoch [50/100], loss:0.000749290\n",
      "epoch [60/100], loss:0.000683004\n",
      "epoch [70/100], loss:0.000331938\n",
      "epoch [80/100], loss:0.000267595\n",
      "epoch [90/100], loss:0.000186949\n",
      "CPU times: user 193 ms, sys: 4.96 ms, total: 198 ms\n",
      "Wall time: 204 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda/lib/python3.6/site-packages/cudf/io/dlpack.py:83: UserWarning: WARNING: cuDF to_dlpack() produces column-major (Fortran order) output. If the output tensor needs to be row major, transpose the output of this function.\n",
      "  return cpp_dlpack.to_dlpack(gdf_cols)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import cudf as gd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.dlpack import from_dlpack\n",
    "\n",
    "path = 'data/electricity_consumption.csv'\n",
    "\n",
    "cudf_data = gd.read_csv(path)\n",
    "\n",
    "#cudf transform\n",
    "minmax = MinMaxScaler().fit(cudf_data.iloc[:, 7].to_array().reshape((-1,1)).astype('float32'))\n",
    "cudf_time_series = minmax.transform(cudf_data.iloc[:, 7].to_array().reshape((-1,1)).astype('float32')).reshape((-1))\n",
    "cudf_time_series = gd.from_pandas(pd.DataFrame(cudf_time_series))\n",
    "\n",
    "\n",
    "# Build the network\n",
    "device = \"cuda:0\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dimension= 32):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.first_layer_encoder = nn.Linear(input_size, hidden_size)\n",
    "        self.second_layer_encoder = nn.Linear(hidden_size, dimension)\n",
    "        self.first_layer_decoder = nn.Linear(dimension, hidden_size)\n",
    "        self.second_layer_decoder = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = nn.functional.relu(self.first_layer_encoder(input))\n",
    "        output = nn.functional.relu(self.second_layer_encoder(output))\n",
    "        decode = nn.functional.relu(self.first_layer_decoder(output))\n",
    "        decode = torch.sigmoid(self.second_layer_decoder(decode))\n",
    "        return decode, output\n",
    "    \n",
    "# Define the training loop\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "input_size = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "def train_model(X, device):\n",
    "    \n",
    "    model = Encoder(input_size, hidden_size=32, dimension=32).to(device)\n",
    "    _X = X.to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        output, _ = model(_X)\n",
    "        loss = criterion(output, _X)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch) % 10 == 0:\n",
    "            print('epoch [{:02d}/{}], loss:{:.9f}'.format(epoch, num_epochs, loss.data))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load data into Tensor\n",
    "X = from_dlpack(cudf_time_series.to_dlpack()).unsqueeze(1).to(device)\n",
    "\n",
    "# Train model\n",
    "model = train_model(X, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We get an overall 2.5 times faster pipeline on GPU with all packages rather than on CPU. Another reason to consider using the RAPIDS.ai suite !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
