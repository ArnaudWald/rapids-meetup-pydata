{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Encoder for cudf vs Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import cudf as gd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Modifying Data\n",
    "\n",
    "We are using the Electrolysia Time-Series Electricity Consumption Dataset from Kaggle, you can find more details about it [on the Kaggle dataset page](https://www.kaggle.com/utathya/electricity-consumption).\n",
    "\n",
    "Just for kicks, we can take this opportunity to compare loading times on CPU with `pandas` and GPU with `cuDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/electricity_consumption.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.5 ms, sys: 7.79 ms, total: 46.3 ms\n",
      "Wall time: 44.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pandas reading time\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 238 ms, sys: 32.3 ms, total: 270 ms\n",
      "Wall time: 269 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#pandas Transform\n",
    "minmax = MinMaxScaler().fit(df.iloc[:, 7].values.reshape((-1,1)).astype('float32'))\n",
    "df_time_series = minmax.transform(df.iloc[:, 7].values.reshape((-1,1)).astype('float32')).reshape((-1))\n",
    "df_time_series = pd.DataFrame(df_time_series)\n",
    "df_time_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_original = pd.to_datetime(df.iloc[:, 0]).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 11.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#cudf reading\n",
    "cudf_data = gd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 119 ms, sys: 12.7 ms, total: 132 ms\n",
      "Wall time: 130 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#cudf transform\n",
    "minmax = MinMaxScaler().fit(cudf_data.iloc[:, 7].to_array().reshape((-1,1)).astype('float32'))\n",
    "cudf_time_series = minmax.transform(cudf_data.iloc[:, 7].to_array().reshape((-1,1)).astype('float32')).reshape((-1))\n",
    "cudf_time_series = gd.from_pandas(pd.DataFrame(cudf_time_series))\n",
    "cudf_time_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Encoder\n",
    "\n",
    "Now what we want to do is to create a representation of data  or an encoding of data (for ex: a intermediate layer in resnet) . So, we will use a simple MLP to do that. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bd3d209a6799>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Building a Pytorch MLP model to get an intermediate representation of Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "## Building a Pytorch MLP model to get an intermediate representation of Data\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dimension= 32):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.first_layer_encoder = nn.Linear(input_size, hidden_size)\n",
    "        self.second_layer_encoder = nn.Linear(hidden_size, dimension)\n",
    "        self.first_layer_decoder = nn.Linear(dimension, hidden_size)\n",
    "        self.second_layer_decoder = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = nn.functional.relu(self.first_layer_encoder(input))\n",
    "        output = nn.functional.relu(self.second_layer_encoder(output))\n",
    "        decode = nn.functional.relu(self.first_layer_decoder(output))\n",
    "        decode = nn.functional.sigmoid(self.second_layer_decoder(decode))\n",
    "        return decode, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "input_size = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = Encoder(input_size, hidden_size=32, dimension=32)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda/lib/python3.6/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:0.1840\n",
      "epoch [2/100], loss:0.1629\n",
      "epoch [3/100], loss:0.1463\n",
      "epoch [4/100], loss:0.1271\n",
      "epoch [5/100], loss:0.1055\n",
      "epoch [6/100], loss:0.0814\n",
      "epoch [7/100], loss:0.0570\n",
      "epoch [8/100], loss:0.0353\n",
      "epoch [9/100], loss:0.0196\n",
      "epoch [10/100], loss:0.0116\n",
      "epoch [11/100], loss:0.0099\n",
      "epoch [12/100], loss:0.0111\n",
      "epoch [13/100], loss:0.0130\n",
      "epoch [14/100], loss:0.0146\n",
      "epoch [15/100], loss:0.0157\n",
      "epoch [16/100], loss:0.0165\n",
      "epoch [17/100], loss:0.0170\n",
      "epoch [18/100], loss:0.0173\n",
      "epoch [19/100], loss:0.0175\n",
      "epoch [20/100], loss:0.0177\n",
      "epoch [21/100], loss:0.0177\n",
      "epoch [22/100], loss:0.0177\n",
      "epoch [23/100], loss:0.0176\n",
      "epoch [24/100], loss:0.0175\n",
      "epoch [25/100], loss:0.0172\n",
      "epoch [26/100], loss:0.0166\n",
      "epoch [27/100], loss:0.0155\n",
      "epoch [28/100], loss:0.0134\n",
      "epoch [29/100], loss:0.0100\n",
      "epoch [30/100], loss:0.0091\n",
      "epoch [31/100], loss:0.0098\n",
      "epoch [32/100], loss:0.0075\n",
      "epoch [33/100], loss:0.0080\n",
      "epoch [34/100], loss:0.0083\n",
      "epoch [35/100], loss:0.0074\n",
      "epoch [36/100], loss:0.0058\n",
      "epoch [37/100], loss:0.0054\n",
      "epoch [38/100], loss:0.0056\n",
      "epoch [39/100], loss:0.0037\n",
      "epoch [40/100], loss:0.0034\n",
      "epoch [41/100], loss:0.0032\n",
      "epoch [42/100], loss:0.0022\n",
      "epoch [43/100], loss:0.0014\n",
      "epoch [44/100], loss:0.0018\n",
      "epoch [45/100], loss:0.0011\n",
      "epoch [46/100], loss:0.0007\n",
      "epoch [47/100], loss:0.0010\n",
      "epoch [48/100], loss:0.0009\n",
      "epoch [49/100], loss:0.0006\n",
      "epoch [50/100], loss:0.0009\n",
      "epoch [51/100], loss:0.0010\n",
      "epoch [52/100], loss:0.0008\n",
      "epoch [53/100], loss:0.0009\n",
      "epoch [54/100], loss:0.0010\n",
      "epoch [55/100], loss:0.0009\n",
      "epoch [56/100], loss:0.0008\n",
      "epoch [57/100], loss:0.0009\n",
      "epoch [58/100], loss:0.0008\n",
      "epoch [59/100], loss:0.0007\n",
      "epoch [60/100], loss:0.0007\n",
      "epoch [61/100], loss:0.0007\n",
      "epoch [62/100], loss:0.0006\n",
      "epoch [63/100], loss:0.0005\n",
      "epoch [64/100], loss:0.0005\n",
      "epoch [65/100], loss:0.0005\n",
      "epoch [66/100], loss:0.0004\n",
      "epoch [67/100], loss:0.0004\n",
      "epoch [68/100], loss:0.0005\n",
      "epoch [69/100], loss:0.0004\n",
      "epoch [70/100], loss:0.0004\n",
      "epoch [71/100], loss:0.0004\n",
      "epoch [72/100], loss:0.0004\n",
      "epoch [73/100], loss:0.0004\n",
      "epoch [74/100], loss:0.0004\n",
      "epoch [75/100], loss:0.0003\n",
      "epoch [76/100], loss:0.0003\n",
      "epoch [77/100], loss:0.0003\n",
      "epoch [78/100], loss:0.0003\n",
      "epoch [79/100], loss:0.0003\n",
      "epoch [80/100], loss:0.0003\n",
      "epoch [81/100], loss:0.0002\n",
      "epoch [82/100], loss:0.0002\n",
      "epoch [83/100], loss:0.0002\n",
      "epoch [84/100], loss:0.0002\n",
      "epoch [85/100], loss:0.0002\n",
      "epoch [86/100], loss:0.0002\n",
      "epoch [87/100], loss:0.0002\n",
      "epoch [88/100], loss:0.0002\n",
      "epoch [89/100], loss:0.0002\n",
      "epoch [90/100], loss:0.0002\n",
      "epoch [91/100], loss:0.0002\n",
      "epoch [92/100], loss:0.0002\n",
      "epoch [93/100], loss:0.0002\n",
      "epoch [94/100], loss:0.0001\n",
      "epoch [95/100], loss:0.0001\n",
      "epoch [96/100], loss:0.0001\n",
      "epoch [97/100], loss:0.0001\n",
      "epoch [98/100], loss:0.0001\n",
      "epoch [99/100], loss:0.0001\n",
      "epoch [100/100], loss:0.0001\n",
      "CPU times: user 3.76 s, sys: 6.95 s, total: 10.7 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# pandas run time\n",
    "X = Variable(torch.from_numpy(df_time_series.values).float(), requires_grad=False)\n",
    "for epoch in range(num_epochs):\n",
    "    output, _ = model(X)\n",
    "    loss = criterion(output, X)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder(input_size, hidden_size=32, dimension=32)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:0.1607\n",
      "epoch [2/100], loss:0.1320\n",
      "epoch [3/100], loss:0.1022\n",
      "epoch [4/100], loss:0.0713\n",
      "epoch [5/100], loss:0.0428\n",
      "epoch [6/100], loss:0.0216\n",
      "epoch [7/100], loss:0.0101\n",
      "epoch [8/100], loss:0.0071\n",
      "epoch [9/100], loss:0.0085\n",
      "epoch [10/100], loss:0.0108\n",
      "epoch [11/100], loss:0.0128\n",
      "epoch [12/100], loss:0.0143\n",
      "epoch [13/100], loss:0.0152\n",
      "epoch [14/100], loss:0.0159\n",
      "epoch [15/100], loss:0.0163\n",
      "epoch [16/100], loss:0.0165\n",
      "epoch [17/100], loss:0.0167\n",
      "epoch [18/100], loss:0.0167\n",
      "epoch [19/100], loss:0.0166\n",
      "epoch [20/100], loss:0.0164\n",
      "epoch [21/100], loss:0.0161\n",
      "epoch [22/100], loss:0.0155\n",
      "epoch [23/100], loss:0.0146\n",
      "epoch [24/100], loss:0.0130\n",
      "epoch [25/100], loss:0.0106\n",
      "epoch [26/100], loss:0.0071\n",
      "epoch [27/100], loss:0.0048\n",
      "epoch [28/100], loss:0.0106\n",
      "epoch [29/100], loss:0.0064\n",
      "epoch [30/100], loss:0.0040\n",
      "epoch [31/100], loss:0.0045\n",
      "epoch [32/100], loss:0.0053\n",
      "epoch [33/100], loss:0.0054\n",
      "epoch [34/100], loss:0.0047\n",
      "epoch [35/100], loss:0.0034\n",
      "epoch [36/100], loss:0.0022\n",
      "epoch [37/100], loss:0.0025\n",
      "epoch [38/100], loss:0.0031\n",
      "epoch [39/100], loss:0.0021\n",
      "epoch [40/100], loss:0.0011\n",
      "epoch [41/100], loss:0.0011\n",
      "epoch [42/100], loss:0.0013\n",
      "epoch [43/100], loss:0.0012\n",
      "epoch [44/100], loss:0.0009\n",
      "epoch [45/100], loss:0.0006\n",
      "epoch [46/100], loss:0.0006\n",
      "epoch [47/100], loss:0.0009\n",
      "epoch [48/100], loss:0.0010\n",
      "epoch [49/100], loss:0.0007\n",
      "epoch [50/100], loss:0.0006\n",
      "epoch [51/100], loss:0.0008\n",
      "epoch [52/100], loss:0.0008\n",
      "epoch [53/100], loss:0.0008\n",
      "epoch [54/100], loss:0.0006\n",
      "epoch [55/100], loss:0.0005\n",
      "epoch [56/100], loss:0.0006\n",
      "epoch [57/100], loss:0.0006\n",
      "epoch [58/100], loss:0.0005\n",
      "epoch [59/100], loss:0.0004\n",
      "epoch [60/100], loss:0.0004\n",
      "epoch [61/100], loss:0.0004\n",
      "epoch [62/100], loss:0.0004\n",
      "epoch [63/100], loss:0.0004\n",
      "epoch [64/100], loss:0.0004\n",
      "epoch [65/100], loss:0.0004\n",
      "epoch [66/100], loss:0.0004\n",
      "epoch [67/100], loss:0.0004\n",
      "epoch [68/100], loss:0.0004\n",
      "epoch [69/100], loss:0.0003\n",
      "epoch [70/100], loss:0.0003\n",
      "epoch [71/100], loss:0.0003\n",
      "epoch [72/100], loss:0.0003\n",
      "epoch [73/100], loss:0.0003\n",
      "epoch [74/100], loss:0.0003\n",
      "epoch [75/100], loss:0.0003\n",
      "epoch [76/100], loss:0.0003\n",
      "epoch [77/100], loss:0.0003\n",
      "epoch [78/100], loss:0.0003\n",
      "epoch [79/100], loss:0.0003\n",
      "epoch [80/100], loss:0.0003\n",
      "epoch [81/100], loss:0.0003\n",
      "epoch [82/100], loss:0.0003\n",
      "epoch [83/100], loss:0.0002\n",
      "epoch [84/100], loss:0.0002\n",
      "epoch [85/100], loss:0.0002\n",
      "epoch [86/100], loss:0.0002\n",
      "epoch [87/100], loss:0.0002\n",
      "epoch [88/100], loss:0.0002\n",
      "epoch [89/100], loss:0.0002\n",
      "epoch [90/100], loss:0.0002\n",
      "epoch [91/100], loss:0.0002\n",
      "epoch [92/100], loss:0.0002\n",
      "epoch [93/100], loss:0.0002\n",
      "epoch [94/100], loss:0.0002\n",
      "epoch [95/100], loss:0.0002\n",
      "epoch [96/100], loss:0.0002\n",
      "epoch [97/100], loss:0.0002\n",
      "epoch [98/100], loss:0.0002\n",
      "epoch [99/100], loss:0.0002\n",
      "epoch [100/100], loss:0.0002\n",
      "CPU times: user 2.7 s, sys: 5.68 s, total: 8.38 s\n",
      "Wall time: 843 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#cudf run time\n",
    "X = Variable(torch.from_numpy(cudf_time_series.as_matrix()).float(), requires_grad=False)\n",
    "for epoch in range(num_epochs):\n",
    "    output, _ = model(X)\n",
    "    loss = criterion(output, X)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, encoding = model(X)\n",
    "encoding.shape\n",
    "torch.save(encoding, 'electricity_encoding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = torch.load('electricity_encoding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
